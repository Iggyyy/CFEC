{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58c58883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Layer\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import operator\n",
    "from typing import Union, Tuple, List, Any, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dde7621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.counterfactuals.base import CounterfactualMethod\n",
    "\n",
    "#from src.counterfactuals.constraints import Freeze, OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77d2aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cadex(CounterfactualMethod):\n",
    "    '''\n",
    "    Creates a counterfactual explanation based on a pre-trained model using CADEX method\n",
    "    The model has to be a Keras classifier model, where in the final classification layer, each class label must\n",
    "    have a separate unit.\n",
    "    '''\n",
    "    def __init__(self, pretrained_model, constraints: Optional[List[Any]] = None) -> None:\n",
    "        self.model = pretrained_model\n",
    "        for layer in self.model.layers[2:]:\n",
    "             layer.trainable = False\n",
    "                \n",
    "        self._constraints = constraints if constraints is not None else []\n",
    "        \n",
    "#         modified_input_layer = ModifiedInputLayer()\n",
    "#         model_input = self.original_model.layers[0].input\n",
    "#         model_output = modified_input_layer(self.original_model.layers[0].output)\n",
    "#         for layer in self.original_model.layers[1:]:\n",
    "#             model_output = layer(model_output)\n",
    "        \n",
    "#         self.model = Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "#         for layer in self.model.layers[2:]:\n",
    "#             layer.trainable = False\n",
    "#         print(self.model.summary())\n",
    "            \n",
    "#         self.input_modified = modified_input_layer\n",
    "#         desired = Input(shape=[model_output.shape[1]])\n",
    "#         desired_loss = -K.sum(desired * K.log(self.output), axis=1)\n",
    "#         grad = K.gradients(desired_loss, [self.input])\n",
    "#         self.adv_grad = K.function([self.input, desired], [grad[0]])\n",
    "# Rebuild the model with an input modification layer\n",
    "#         input_mod_layer = ModifiedInputLayer()\n",
    "#         self.input = self.original_model.layers[0].input\n",
    "#         model = input_mod_layer(self.original_model.layers[0].output)\n",
    "#         for layer in self.original_model.layers[1:]:\n",
    "#             model = layer(model)\n",
    "#         self.output = model\n",
    "\n",
    "#         self.model = Model(inputs=self.input, outputs=self.output)\n",
    "#         # Only allow the input modification layer to be trained\n",
    "#         for layer in self.model.layers[2:]:\n",
    "#             layer.trainable = False\n",
    "#         print(self.model.summary())\n",
    "#         self.input_modifier = input_mod_layer\n",
    "        \n",
    "        \n",
    "    def generate(self, x: Union[pd.Series, np.ndarray], max_epoch=100, threshold=0.5) -> Union[pd.DataFrame, np.ndarray]:\n",
    "        original_x = x.copy()\n",
    "        original_y = self.model.predict(original_x)\n",
    "        expected_y = 0 if original_y = 1 else 1\n",
    "        \n",
    "        mask = _get_mask(x, self._constraints) # TODO\n",
    "        \n",
    "        result = None\n",
    "        epoch = 0\n",
    "        for _ in range(max_epoch):\n",
    "            gradient = self._get_gradient(x, mask) # TODO\n",
    "            x = x - gradient\n",
    "            x = correct_categorical(x, threshold)\n",
    "            x = apply_constraints(x)\n",
    "            if self.model.predict(x) == expected_y:\n",
    "                return x\n",
    "            \n",
    "        return None\n",
    "            \n",
    "            \n",
    "    def _get_gradient(x, y, mask):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            y_pred = self.model.predict(x)\n",
    "            loss = tf.reduce_mean(y_pred - y)\n",
    "            \n",
    "    return tape.gradient(loss, model.trainable_variables) * mask\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "class ModifiedInputLayer(Layer):\n",
    "    '''\n",
    "    Input modification layer.\n",
    "    Has a vector of trainable weights which are added to the incoming input.\n",
    "    Subclasses Keras' Layer class and implements 3 abstract methods\n",
    "    '''\n",
    "    def build(self, input_shape):\n",
    "        self._weights = self.add_weight(name='weights', shape=(1, input_shape[1]), initializer='zeros', trainable=True)\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        return x + self._weights\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "    def transform(self, input):\n",
    "        res = input + self.get_weights()[0]\n",
    "        if isinstance(res, pd.DataFrame):\n",
    "            return res.values\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class CadexAdam(Adam):\n",
    "    '''\n",
    "    Adam optimizer, with gradient mask.\n",
    "    The mask is given in the constructor, and used to multiply by the gradients.\n",
    "    get_gradients from the base Optimizer class is overridden to implement this behaviour.\n",
    "    '''\n",
    "    def __init__(self, mask, **kwargs):\n",
    "        self._mask = mask\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def get_gradients(self, loss, params):\n",
    "        return [i * self._mask for i in super().get_gradients(loss, params)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3e1953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('data/model_german.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d566784c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(61, 15) dtype=float32, numpy=\n",
       " array([[-7.14035565e-03, -2.23118439e-02, -1.73734408e-03,\n",
       "         -6.62157254e-06,  1.24929339e-01, -4.41957265e-03,\n",
       "          1.13691650e-02, -2.15552427e-04, -1.28878698e-01,\n",
       "          3.30290961e-04,  1.08505548e-04,  5.46226162e-04,\n",
       "         -7.38163799e-05,  1.02641527e-02,  2.47910211e-05],\n",
       "        [-1.83521714e-02, -5.75711131e-02,  2.50781828e-04,\n",
       "         -1.19478325e-04, -5.79149113e-04, -6.55479953e-02,\n",
       "          9.55273584e-02,  1.01216661e-04, -6.63950283e-04,\n",
       "          6.76028547e-04, -1.53302404e-04,  2.37043074e-04,\n",
       "          3.07430346e-05,  8.81974818e-04, -4.32097659e-06],\n",
       "        [-2.80384859e-03, -1.16936997e-01, -2.01816894e-02,\n",
       "          1.25808408e-04,  2.95345322e-03, -3.54610942e-03,\n",
       "          5.36744818e-02,  4.37307099e-05, -1.65244483e-03,\n",
       "          1.57287531e-03,  2.75312428e-04,  1.36759272e-03,\n",
       "          7.06414285e-05,  3.58456895e-02,  7.06467981e-05],\n",
       "        [ 1.66258687e-04, -1.11084373e-03, -6.80626486e-04,\n",
       "          2.78337306e-04,  1.97650370e-04, -7.63011747e-04,\n",
       "          2.57537700e-03,  5.47066884e-05,  1.87906742e-04,\n",
       "          4.36415401e-04, -1.30124972e-04,  4.58159222e-04,\n",
       "          1.29800566e-04,  3.47596221e-03, -3.49000402e-05],\n",
       "        [ 6.38876157e-03,  5.89798503e-02,  2.79358844e-03,\n",
       "          8.44809620e-05, -1.54374109e-04,  4.27380018e-02,\n",
       "         -3.10901110e-03,  2.93907215e-05,  1.75239574e-02,\n",
       "         -6.89540990e-04,  3.68179462e-04, -5.92908298e-04,\n",
       "          1.61938733e-04, -2.63513029e-02,  5.86733295e-05],\n",
       "        [-2.94707040e-03, -4.31364914e-03, -1.21167628e-03,\n",
       "         -1.85288911e-04,  3.53730866e-03, -3.71640665e-03,\n",
       "          3.97524098e-03, -4.59781695e-05, -4.01682890e-04,\n",
       "         -1.61061020e-04, -1.10713881e-04, -6.91598863e-04,\n",
       "          1.52507622e-04,  2.38320814e-03,  9.05549969e-05],\n",
       "        [-5.52933838e-04, -5.85725764e-04, -1.08143571e-03,\n",
       "         -2.08990663e-04,  1.29795657e-03, -8.69416224e-04,\n",
       "         -2.84122129e-04,  1.37659590e-05, -1.36539096e-03,\n",
       "          1.24199578e-05,  2.70023505e-04, -2.65654817e-05,\n",
       "          6.67693093e-05,  1.33567525e-03,  2.67283584e-04],\n",
       "        [ 3.71879229e-04,  1.82490359e-04,  3.36934871e-04,\n",
       "         -2.91169825e-04, -2.46353913e-04,  3.91729118e-04,\n",
       "          9.85242077e-05, -6.48661153e-05, -1.94858905e-04,\n",
       "          8.01812857e-05,  1.64446916e-04,  4.27516730e-04,\n",
       "         -1.34074551e-04,  2.24020868e-03,  2.39007786e-05],\n",
       "        [-4.19040248e-02, -2.34803627e-03,  1.13730750e-03,\n",
       "          9.17379948e-05,  6.32740110e-02, -4.56986390e-02,\n",
       "          1.14294969e-01, -1.20525103e-04,  5.65682654e-04,\n",
       "         -1.09966204e-04, -2.76383711e-04,  9.73167771e-04,\n",
       "          9.99698823e-05,  1.00509357e-02, -3.55748634e-05],\n",
       "        [ 3.35498480e-05,  6.02615008e-04,  4.20849246e-04,\n",
       "          1.19681004e-04,  2.47175572e-04,  3.58233083e-04,\n",
       "         -5.17977227e-04, -2.27849174e-04, -1.38762203e-04,\n",
       "          3.66549881e-04, -6.95916824e-05,  5.49816177e-04,\n",
       "          2.63227266e-04, -1.35975878e-03,  2.57953856e-04],\n",
       "        [ 2.40816250e-01,  3.40777367e-01,  2.65296489e-01,\n",
       "         -1.49510743e-04, -1.33134413e-03,  9.13185477e-02,\n",
       "         -2.05409423e-01, -6.07219263e-05,  8.54749465e-04,\n",
       "         -7.71322229e-05,  1.38053467e-04, -8.28410848e-05,\n",
       "         -6.14452874e-05, -4.52241220e-05,  1.36524613e-04],\n",
       "        [-3.36799421e-04, -1.09628728e-03,  1.46150996e-05,\n",
       "          1.17236312e-04, -4.02313890e-05,  1.44143181e-04,\n",
       "          1.40176655e-03,  1.68802580e-04, -7.13033078e-04,\n",
       "         -2.35688130e-04, -1.78994029e-04,  3.23302738e-05,\n",
       "          2.21948751e-04,  2.88020587e-03,  2.33040759e-04],\n",
       "        [ 1.08136311e-02,  2.60989219e-01,  1.61435117e-03,\n",
       "          1.50229404e-04, -1.12186093e-03,  1.05698442e-03,\n",
       "         -5.05419541e-03,  2.27266228e-05,  2.38427278e-02,\n",
       "         -1.23586084e-04, -1.21751273e-05,  2.81497079e-04,\n",
       "         -1.23646896e-05, -2.37384392e-03,  3.22944252e-05],\n",
       "        [ 1.19866082e-03,  2.53202557e-03, -4.12108697e-04,\n",
       "          4.46839040e-05, -9.99747310e-04,  2.29179673e-03,\n",
       "         -2.38665775e-03, -4.03901533e-04, -8.54503887e-05,\n",
       "         -1.40548218e-05, -8.78006904e-05,  6.88660293e-06,\n",
       "         -3.32479249e-06, -2.45092181e-03, -1.93035579e-04],\n",
       "        [-1.24068232e-04,  3.75129603e-04,  2.86732393e-04,\n",
       "          1.17388503e-04,  4.69327759e-04, -1.00714926e-04,\n",
       "         -3.87015811e-04, -2.05266879e-05, -1.95789471e-05,\n",
       "         -6.87984284e-05, -1.27504492e-04,  5.67851937e-04,\n",
       "         -2.59440392e-04, -4.98211128e-04,  2.78345484e-04],\n",
       "        [-1.98416784e-03, -4.87215770e-03, -7.53093336e-05,\n",
       "         -5.70978555e-05,  6.95664668e-04, -1.61356782e-03,\n",
       "          4.63417824e-03,  8.26682444e-05, -1.84076373e-04,\n",
       "         -1.48507097e-05, -9.89689725e-05,  1.22567129e-04,\n",
       "         -1.15539209e-04,  5.55832637e-03,  1.54601250e-04],\n",
       "        [-1.50747865e-03, -4.31559794e-03, -2.11095088e-04,\n",
       "          4.16726107e-05,  3.51672119e-04, -9.62783408e-04,\n",
       "          4.64424025e-03, -8.79439467e-05, -7.73927663e-04,\n",
       "          1.97548361e-04,  1.19558543e-04, -1.46804858e-04,\n",
       "          3.68410401e-04,  1.84083218e-03, -9.43634950e-06],\n",
       "        [-3.71480011e-03, -2.42002886e-02,  1.11030811e-03,\n",
       "          2.50233163e-04,  2.95023597e-03, -1.87032344e-03,\n",
       "          8.49743113e-02, -6.99268712e-05, -2.13368014e-02,\n",
       "          3.00540443e-04,  2.09349382e-04, -8.37068364e-06,\n",
       "         -2.27835699e-06,  1.79214165e-01,  1.12290800e-05],\n",
       "        [ 9.74981580e-03,  1.07074641e-01,  2.21245619e-03,\n",
       "          4.03552840e-05, -2.89497338e-03,  3.74161545e-03,\n",
       "         -2.25474890e-02,  3.27347589e-05,  1.78876088e-03,\n",
       "         -1.39520038e-04,  4.35119728e-06, -2.35812098e-04,\n",
       "          6.88550426e-05, -1.23534575e-02, -2.82342575e-04],\n",
       "        [ 5.20939706e-04, -1.15247181e-04, -4.67693782e-04,\n",
       "          1.85600104e-04,  1.40551361e-04, -5.73584111e-06,\n",
       "         -5.53411432e-04,  5.45269795e-05, -3.10863688e-04,\n",
       "         -2.95684498e-04,  1.85534795e-04,  1.16704156e-04,\n",
       "          7.00202654e-05, -6.64952386e-05, -5.58142492e-05],\n",
       "        [-2.66887154e-03, -5.11502568e-03, -3.88300105e-04,\n",
       "          1.05587678e-05,  3.30166193e-03, -2.08680960e-03,\n",
       "          1.37054762e-02,  2.83856643e-05, -2.57253135e-03,\n",
       "         -2.10237893e-04, -1.49939980e-04, -2.73939077e-04,\n",
       "         -4.15159084e-05,  2.68499856e-03,  9.76044248e-05],\n",
       "        [ 1.38439180e-04,  6.14573306e-04,  9.41108679e-04,\n",
       "         -1.25157821e-04, -1.54071953e-03,  4.35203314e-04,\n",
       "         -7.34958739e-04, -1.00118916e-04,  1.72331301e-03,\n",
       "          2.38715875e-04,  1.25169681e-04,  1.63493212e-03,\n",
       "         -4.08659544e-05, -3.14301171e-04, -3.36826379e-05],\n",
       "        [-1.68566388e-04, -1.80007482e-04, -2.58257001e-04,\n",
       "          2.32968741e-04,  2.95131358e-05, -5.78812556e-04,\n",
       "          1.87666636e-04, -7.01851823e-05, -2.79538392e-04,\n",
       "         -8.34041421e-05,  4.05438186e-05, -3.96698670e-05,\n",
       "         -3.68572888e-04, -6.00222193e-05,  1.12600479e-04],\n",
       "        [ 2.81489850e-03,  4.14482318e-03,  1.65724265e-03,\n",
       "         -4.97675501e-07, -1.95281790e-03,  3.85453319e-03,\n",
       "         -1.42488163e-02,  5.07889199e-05,  2.57847575e-03,\n",
       "         -3.36209079e-04,  1.36106624e-04, -9.76277632e-04,\n",
       "         -3.18670471e-04, -1.37507543e-02, -2.60593170e-05],\n",
       "        [ 3.71376518e-05,  6.25627465e-04,  3.23331449e-04,\n",
       "         -7.42667762e-05, -9.78118987e-05, -9.12312607e-05,\n",
       "         -7.25442311e-04, -7.13168847e-05,  9.40417813e-05,\n",
       "          1.68380444e-04,  2.81640860e-05,  1.27907057e-04,\n",
       "         -1.06514206e-04, -1.89946659e-04,  1.97058791e-04],\n",
       "        [ 3.25295783e-04,  1.40511111e-04, -7.44691351e-05,\n",
       "         -1.92082167e-04, -2.52423852e-05,  1.91180035e-04,\n",
       "          1.21253281e-04,  1.53987712e-04,  3.59520724e-04,\n",
       "          1.99549628e-04, -7.84029544e-05,  7.96623681e-06,\n",
       "          8.22518487e-05, -2.83792178e-04,  1.57270297e-05],\n",
       "        [-1.82597351e-03, -1.66000077e-03, -9.22598876e-04,\n",
       "         -7.16247814e-05,  1.46207889e-03, -1.57384179e-03,\n",
       "          1.39450992e-03, -2.79906089e-06, -4.74455504e-04,\n",
       "         -4.17718547e-05,  7.87485333e-05, -4.37924813e-04,\n",
       "         -1.44381178e-04,  2.27764202e-03,  5.82063149e-05],\n",
       "        [-1.29976380e-03, -6.97120326e-04, -1.53981347e-03,\n",
       "          9.08083020e-05,  1.21169398e-03, -1.15996669e-03,\n",
       "          1.09913270e-03,  5.43889291e-05, -1.91948970e-03,\n",
       "          1.43257239e-05,  2.81714601e-04,  1.17004813e-04,\n",
       "          3.22348351e-05,  4.84233373e-04, -6.30254071e-05],\n",
       "        [-8.08116123e-02, -2.11153012e-02, -4.10257257e-04,\n",
       "          9.95547161e-05,  6.29068986e-02, -1.60023617e-03,\n",
       "          9.80211273e-02,  3.56425589e-05,  4.76903224e-04,\n",
       "          9.54095391e-04, -1.88615522e-04,  6.40458195e-04,\n",
       "         -7.59570685e-06,  3.95545512e-02,  7.56793888e-05],\n",
       "        [ 1.16301456e-03,  3.10399511e-04, -2.09404912e-04,\n",
       "          5.62938112e-05,  3.35374905e-04,  6.97198790e-04,\n",
       "         -7.38103292e-04,  4.99265916e-05,  5.36719221e-04,\n",
       "          3.60885198e-04,  2.28683915e-04, -8.26575269e-05,\n",
       "          2.73386831e-04, -3.01769655e-03, -1.14823248e-04],\n",
       "        [ 2.66355491e-04,  2.15777699e-02,  6.51021837e-04,\n",
       "          2.79090455e-05, -6.24531996e-04,  1.38518211e-04,\n",
       "         -9.23518930e-03, -1.07841857e-04, -3.13026278e-04,\n",
       "          2.31402941e-04, -8.20231799e-06,  2.34304258e-04,\n",
       "         -1.12152607e-04, -9.25493985e-03, -1.45404760e-04],\n",
       "        [-5.19479858e-03, -8.88494216e-03, -1.61820650e-03,\n",
       "         -5.54728394e-05,  1.45868352e-03, -1.78950047e-03,\n",
       "          2.61261314e-02,  1.70671454e-04, -1.08997419e-03,\n",
       "          5.95964026e-04,  2.22678049e-04,  7.09758024e-04,\n",
       "          1.29908789e-04,  4.16143276e-02,  1.55871050e-04],\n",
       "        [ 4.91255894e-04, -6.87638298e-04,  2.33263447e-04,\n",
       "          6.87312131e-05, -4.56006092e-04,  2.12886982e-04,\n",
       "          1.22807978e-03,  1.60158816e-05,  4.78177099e-04,\n",
       "         -9.28062218e-05,  8.34373786e-05, -9.70427209e-06,\n",
       "         -9.57083321e-05,  7.29238905e-04, -8.07539764e-05],\n",
       "        [ 3.19207460e-03,  3.29477317e-03,  2.65304302e-03,\n",
       "         -1.16408220e-04, -1.90402474e-03,  2.56747101e-03,\n",
       "         -4.34476044e-03,  8.87773058e-05,  3.42153478e-03,\n",
       "         -4.00735553e-05, -3.82223545e-04, -2.84929120e-04,\n",
       "         -5.38955355e-05, -5.89370914e-03, -7.48512502e-06],\n",
       "        [ 6.91027613e-04,  8.03759620e-02,  6.87533538e-05,\n",
       "         -1.74832705e-04,  1.46267150e-04,  7.32446834e-02,\n",
       "         -9.71873756e-04, -2.89679796e-04, -3.72644194e-04,\n",
       "          1.78346323e-04,  1.75486406e-04,  2.67472467e-04,\n",
       "         -1.75239271e-04, -2.16804235e-03, -6.87037318e-05],\n",
       "        [-2.83920881e-03, -3.74311302e-03, -1.59186078e-03,\n",
       "          6.14437740e-05,  1.41334324e-03, -2.49134796e-03,\n",
       "          6.15760335e-04, -6.90631277e-05, -1.47947471e-03,\n",
       "         -2.79863656e-04, -1.89646016e-04,  9.64687497e-05,\n",
       "         -1.36003946e-05,  4.59235767e-03,  5.95233978e-05],\n",
       "        [ 8.18816014e-04,  6.64693071e-04,  5.25063777e-04,\n",
       "         -4.83547665e-05, -1.40515668e-03,  1.35509967e-04,\n",
       "         -4.77836700e-04, -1.04419596e-04,  3.62258463e-04,\n",
       "          4.34128015e-04, -1.98246817e-05,  1.69582199e-04,\n",
       "         -1.74921588e-04, -2.03499309e-04,  1.71709835e-04],\n",
       "        [ 2.90404423e-04,  5.55742125e-04,  7.73527136e-04,\n",
       "         -1.09381435e-04, -6.18096790e-04,  1.15958904e-03,\n",
       "          1.51689798e-01,  5.36435909e-05,  3.69350804e-04,\n",
       "          6.88266126e-04, -3.94527160e-04,  1.12748379e-03,\n",
       "          1.65437115e-04,  6.67270157e-04,  1.91723753e-04],\n",
       "        [-1.75876031e-03, -2.54556607e-03,  5.77394501e-04,\n",
       "         -6.42535597e-05, -1.51087786e-03, -1.05321140e-03,\n",
       "          1.34460989e-03, -4.10685097e-05,  6.95896219e-04,\n",
       "         -4.76577043e-07, -2.45409465e-05,  9.56379110e-04,\n",
       "         -5.80137785e-05,  2.34236941e-03, -1.24385551e-04],\n",
       "        [ 3.09777941e-04,  6.47850335e-04,  3.62927007e-04,\n",
       "         -5.68145479e-05, -4.08623542e-04,  3.52303963e-04,\n",
       "         -8.78541439e-04,  1.14350813e-04, -6.23197411e-04,\n",
       "         -6.52885064e-05, -5.04595519e-04,  7.00411270e-04,\n",
       "          1.39175667e-04, -7.36996299e-04,  1.88967038e-04],\n",
       "        [ 9.44992155e-03,  4.01476286e-02, -6.41191611e-04,\n",
       "         -7.72793865e-05,  1.52604526e-03,  7.12937862e-02,\n",
       "         -6.12167828e-03,  6.08498958e-05, -4.21384466e-04,\n",
       "          3.83098741e-05, -3.15749421e-05,  8.62719389e-05,\n",
       "         -2.83402565e-04, -1.23950364e-02,  8.20514833e-05],\n",
       "        [ 2.44628231e-04, -2.13574094e-04, -2.55712279e-04,\n",
       "         -9.76920710e-05,  1.51771470e-04,  4.11812856e-04,\n",
       "         -3.11513577e-05, -5.10073878e-05, -1.26894360e-04,\n",
       "          1.26632076e-04,  2.99639825e-04,  2.27506709e-04,\n",
       "         -1.75696259e-04, -9.41712118e-04,  1.84522833e-06],\n",
       "        [-2.83400062e-04, -7.99674424e-04,  1.25449937e-04,\n",
       "          1.62883764e-04,  2.04917771e-04, -2.15101361e-04,\n",
       "          1.70393614e-04, -4.65407356e-06, -9.53835843e-05,\n",
       "         -4.39261057e-04, -2.08382480e-04,  3.63681378e-04,\n",
       "         -6.30041250e-05,  3.48575599e-03, -3.44940432e-04],\n",
       "        [ 2.57432424e-02,  3.30655538e-02,  7.55765126e-04,\n",
       "         -5.93994519e-05,  1.37831696e-04,  6.86822981e-02,\n",
       "         -2.95946910e-03,  4.17021838e-05,  2.13708356e-02,\n",
       "          7.41932192e-04, -1.99250178e-04,  3.35646677e-04,\n",
       "          9.06103596e-05, -1.44292399e-01, -1.36344970e-04],\n",
       "        [-2.23422609e-03, -1.71120360e-03, -8.46570110e-05,\n",
       "          2.16080807e-05, -1.03330181e-03, -9.49389592e-04,\n",
       "          1.11084851e-03, -1.37044626e-05, -1.58547511e-04,\n",
       "         -2.59829947e-04,  1.08362554e-04, -2.59283232e-04,\n",
       "          1.55340269e-04,  9.23616637e-04,  7.58498936e-06],\n",
       "        [ 1.23762095e-03,  2.13235081e-03,  1.91193249e-05,\n",
       "         -1.92379171e-04,  1.37667914e-04,  2.18480942e-03,\n",
       "         -1.57523656e-03, -1.29478372e-04, -6.98519580e-04,\n",
       "          8.76939957e-05,  4.78671645e-05,  9.89911496e-05,\n",
       "          7.12723631e-05, -3.07606906e-03,  7.46676233e-06],\n",
       "        [ 1.01806480e-03,  2.48763384e-03,  9.11698560e-04,\n",
       "          7.84184958e-05, -7.09986198e-04,  1.11335632e-03,\n",
       "         -9.68771579e-04, -6.92581598e-05,  9.37968120e-02,\n",
       "          7.39175710e-04,  2.74615246e-04,  9.85450461e-04,\n",
       "          1.00707257e-06, -1.23009703e-03,  6.72033057e-05],\n",
       "        [-2.65547843e-03, -4.08875383e-03, -1.54104130e-03,\n",
       "         -2.31431841e-04,  2.75465637e-03, -5.18223387e-04,\n",
       "          3.96360410e-03, -8.75260375e-05, -8.02473282e-04,\n",
       "          5.45176503e-04, -3.56414675e-05,  7.22074881e-04,\n",
       "         -3.27362286e-05,  2.95630079e-02, -1.97911912e-04],\n",
       "        [ 2.00293888e-03,  1.75579742e-03,  1.62504753e-03,\n",
       "         -5.01931718e-05, -1.11770700e-03,  1.81892398e-03,\n",
       "         -7.40802498e-04,  1.25373888e-04,  1.23203371e-03,\n",
       "          5.36823762e-04,  1.53677975e-04,  7.00854871e-05,\n",
       "          2.58743603e-06, -1.80054037e-03,  1.38039031e-04],\n",
       "        [ 1.40231772e-04,  5.45084942e-04, -2.41290079e-04,\n",
       "          7.20505050e-05,  2.79215761e-02,  7.15067144e-04,\n",
       "          1.94036751e-04, -2.48469914e-05, -1.14786671e-04,\n",
       "         -3.77037097e-04,  8.36370382e-05, -8.50132346e-05,\n",
       "         -2.94614147e-05,  3.93226859e-04,  8.02401919e-05],\n",
       "        [ 1.51382817e-04, -1.33629044e-04, -9.40084283e-06,\n",
       "         -1.76762172e-04,  8.04781375e-05,  1.60745898e-04,\n",
       "         -4.36421396e-05,  1.03277795e-04,  1.06412881e-04,\n",
       "          1.16638112e-04,  1.82510557e-04,  6.75053889e-05,\n",
       "         -1.14622584e-04,  9.98979958e-05, -1.15686438e-04],\n",
       "        [-1.39500876e-03, -4.39128373e-04,  1.47480343e-04,\n",
       "          3.13332799e-04, -3.73546063e-04, -1.55429216e-03,\n",
       "         -1.77988462e-04,  5.34403662e-05, -2.32892053e-05,\n",
       "         -1.88956023e-04, -2.13551975e-04,  6.54353295e-04,\n",
       "         -1.63222459e-04,  1.52444863e-03,  7.47684244e-05],\n",
       "        [-1.04003388e-03, -3.99074896e-04, -4.01540456e-06,\n",
       "         -8.55291655e-05,  7.48970255e-04, -7.42758159e-04,\n",
       "          6.54805801e-04, -5.42492853e-05, -3.15818150e-04,\n",
       "          4.82014846e-04,  2.10790982e-04,  2.27369659e-04,\n",
       "          4.12262416e-05,  2.83226091e-02, -1.62588593e-04],\n",
       "        [ 2.29184167e-03,  1.95315853e-03,  1.45936711e-03,\n",
       "         -1.72326094e-04, -1.32942200e-03,  2.71553919e-03,\n",
       "         -1.43630942e-03,  1.37024021e-04,  1.18512276e-03,\n",
       "          1.75277906e-04,  1.44978971e-04,  1.67481136e-03,\n",
       "          7.76903107e-05, -2.48040399e-03, -5.99095547e-05],\n",
       "        [ 2.17650179e-03,  2.14226730e-03,  1.23289152e-04,\n",
       "         -1.83089374e-04, -6.15172205e-04,  1.60067459e-03,\n",
       "         -1.64182426e-03,  2.67059047e-04,  1.84504536e-03,\n",
       "          7.17931835e-06, -3.52765550e-04,  3.23979475e-04,\n",
       "         -6.70842492e-05, -2.95502134e-03, -6.31283256e-05],\n",
       "        [-2.39842746e-04, -6.09246199e-04,  7.56201742e-04,\n",
       "         -5.90648415e-05,  5.34444116e-04, -7.78990507e-05,\n",
       "          3.28916096e-04, -9.02993270e-06,  6.40072176e-05,\n",
       "          5.52864396e-04,  8.53562378e-05,  3.86541011e-04,\n",
       "         -1.72174216e-04,  1.09056443e-01, -4.84746815e-05],\n",
       "        [-8.52605735e-04, -8.90687341e-04, -1.12405268e-03,\n",
       "          1.91918865e-04,  1.35280518e-03, -1.00736902e-03,\n",
       "          9.85007617e-04, -5.63152425e-05, -3.40551720e-04,\n",
       "          4.37363284e-04,  5.16218824e-05, -6.60603284e-04,\n",
       "         -5.34919673e-05,  1.12185290e-03,  4.30641885e-05],\n",
       "        [ 4.92496155e-02,  1.23225592e-01,  1.76361075e-03,\n",
       "          7.62042400e-05, -1.68118358e-03,  2.17235344e-03,\n",
       "         -1.03615681e-02,  9.81080084e-05,  5.91068878e-04,\n",
       "          2.27945420e-04, -1.84753138e-04,  1.73897672e-04,\n",
       "          1.15726842e-04, -1.25271771e-02,  1.39088970e-05],\n",
       "        [-7.39323348e-03, -1.89544931e-02,  1.79899143e-04,\n",
       "          2.54791987e-04, -2.77355022e-04, -1.05027133e-03,\n",
       "          6.77574659e-04,  8.27217009e-05,  8.59246938e-05,\n",
       "         -5.49726537e-04, -1.77698035e-04, -5.90583018e-04,\n",
       "         -1.37668656e-04,  2.07774118e-02,  1.03790313e-04],\n",
       "        [ 2.86068389e-04,  6.86223735e-04,  3.60705220e-04,\n",
       "         -6.32076990e-07, -3.43562802e-04,  1.18253112e-03,\n",
       "         -1.49034010e-03,  6.03364970e-05,  1.03016803e-03,\n",
       "          1.51152039e-04,  1.25981343e-04,  3.48778267e-04,\n",
       "         -3.68961337e-04, -7.51090352e-04, -1.08748667e-04],\n",
       "        [-7.31786713e-07,  1.46342398e-04, -4.42406803e-04,\n",
       "         -9.98510441e-05,  1.13291154e-03,  2.33576458e-04,\n",
       "         -4.87322657e-04, -2.20342146e-04, -1.41477806e-03,\n",
       "         -4.14400565e-05, -2.01715375e-05, -8.36536274e-05,\n",
       "         -1.90011066e-04, -1.27960031e-03, -7.54977737e-05]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(15,) dtype=float32, numpy=\n",
       " array([ 0.14752547,  0.17422931,  0.11036779, -0.03248561,  0.05058146,\n",
       "         0.1428893 ,  0.06312031, -0.01020286,  0.15492779,  0.03065793,\n",
       "         0.05987438,  0.05883408, -0.01116239,  0.03035079, -0.04223799],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(15, 2) dtype=float32, numpy=\n",
       " array([[-0.47746015,  0.5895334 ],\n",
       "        [-0.48605183,  0.8673609 ],\n",
       "        [ 0.14133321,  0.78512275],\n",
       "        [ 0.02778761,  0.03920808],\n",
       "        [ 0.37943047, -0.40812021],\n",
       "        [-0.7855363 ,  0.1421509 ],\n",
       "        [ 0.696404  , -0.62202674],\n",
       "        [ 0.09646349, -0.34019458],\n",
       "        [-0.31743073,  0.44903517],\n",
       "        [ 0.3280957 ,  0.5040137 ],\n",
       "        [-0.32581106, -0.25221232],\n",
       "        [ 0.08945096,  0.3598488 ],\n",
       "        [ 0.2350615 ,  0.05886156],\n",
       "        [ 0.7525692 , -0.7478425 ],\n",
       "        [ 0.27164042, -0.33934093]], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(2,) dtype=float32, numpy=array([-0.08014521,  0.08014526], dtype=float32)>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in model.layers[2:]:\n",
    "    layer.trainable = False\n",
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce2dcbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 61)]              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 15)                930       \n",
      "                                                                 \n",
      " modified_input_layer_4 (Mod  (None, 15)               15        \n",
      " ifiedInputLayer)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 32        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 977\n",
      "Trainable params: 930\n",
      "Non-trainable params: 47\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cadex = Cadex(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71f9be3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 61)]              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 15)                930       \n",
      "                                                                 \n",
      " modified_input_layer (Modif  (None, 15)               15        \n",
      " iedInputLayer)                                                  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 32        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 977\n",
      "Trainable params: 930\n",
      "Non-trainable params: 47\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cadex = Cadex(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccb6b6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 15)                930       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 32        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 962\n",
      "Trainable params: 930\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc9e122b",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "No gradient defined for operation'IteratorGetNext' (op type: IteratorGetNext). In general every operation must have an associated `@tf.RegisterGradient` for correct autodiff, which this op is lacking. If you want to pretend this operation is a constant in your program, you may insert `tf.stop_gradient`. This can be useful to silence the error in cases where you know gradients are not needed, e.g. the forward pass of tf.custom_gradient. Please see more details in https://www.tensorflow.org/api_docs/python/tf/custom_gradient.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_722/1620212934.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## Why does not it work?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0myPred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;31m#print(yPred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myPred\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0myTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/studies/thesis/counterfactuals/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/studies/thesis/counterfactuals/venv/lib/python3.9/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    624\u001b[0m               \u001b[0mgrad_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_grad_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m               raise LookupError(\n\u001b[0m\u001b[1;32m    627\u001b[0m                   \u001b[0;34m\"No gradient defined for operation\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                   \u001b[0;34mf\"'{op.name}' (op type: {op.type}). \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: No gradient defined for operation'IteratorGetNext' (op type: IteratorGetNext). In general every operation must have an associated `@tf.RegisterGradient` for correct autodiff, which this op is lacking. If you want to pretend this operation is a constant in your program, you may insert `tf.stop_gradient`. This can be useful to silence the error in cases where you know gradients are not needed, e.g. the forward pass of tf.custom_gradient. Please see more details in https://www.tensorflow.org/api_docs/python/tf/custom_gradient."
     ]
    }
   ],
   "source": [
    "model = load_model('data/model_german.h5')\n",
    "x = tf.ones((1, 61), dtype=tf.float32)\n",
    "yTrue =  tf.ones((1, 61), dtype=tf.float32)\n",
    "## Why does not it work?\n",
    "with tf.GradientTape() as tape:\n",
    "  yPred = model.predict(x)\n",
    "  #print(yPred)\n",
    "  loss = tf.reduce_mean(yPred-yTrue)\n",
    "\n",
    "gradients = tape.gradient(loss, model.trainable_variables)\n",
    "print(gradients)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
